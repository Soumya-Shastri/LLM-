{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **CREATING TOKENS**"
      ],
      "metadata": {
        "id": "BTUQj69Ct0Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding =\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "print(\"Total number of characters:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "id": "Rh3MmLbds1j6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d732a7-5a08-4a05-9921-e024a5d38cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sent = \"Hello, I am waiting for my turn since morning.\"\n",
        "res = re.split(r'(\\s)', sent)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "qBwtU-Lzs1l1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae2cb29-c33c-4e9c-b35f-470bffd6cb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'I', ' ', 'am', ' ', 'waiting', ' ', 'for', ' ', 'my', ' ', 'turn', ' ', 'since', ' ', 'morning.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = re.split(r'([,.] |\\s)', sent)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "K3ljPFSss1qY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f76095-aafc-4571-d041-2a87f29c1d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ', ', 'I', ' ', 'am', ' ', 'waiting', ' ', 'for', ' ', 'my', ' ', 'turn', ' ', 'since', ' ', 'morning.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [i for i in res if i.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "Ahce5ayqs1sN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729d1235-f3ec-46c4-c59c-faf4bceccbfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ', ', 'I', 'am', 'waiting', 'for', 'my', 'turn', 'since', 'morning.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Removing whitepaces**"
      ],
      "metadata": {
        "id": "0oqtr-5pHIy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence  = \" Wonderful ! , you have made a   beautiful picture -- . Could you make it for me ? \"\n",
        "\n",
        "res_re = re.split(r'([,.\"!?;:\\'_()[]{}]|--|\\s)', sentence )\n",
        "res_y = [item.strip() for item in res_re if item.strip()]\n",
        "print(res_y)"
      ],
      "metadata": {
        "id": "Zo4xXC95s1wQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ab89a8-99cf-4a69-afd5-015b520e13c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Wonderful', '!', ',', 'you', 'have', 'made', 'a', 'beautiful', 'picture', '--', '.', 'Could', 'you', 'make', 'it', 'for', 'me', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying this method to the entire \"the-verdict\"**"
      ],
      "metadata": {
        "id": "xoz3Z4SFLbwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([.,!?;:_(){}\\[\\]\\s]|--)', raw_text)\n",
        "res_pre = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(res_pre[:200])"
      ],
      "metadata": {
        "id": "KRYWirr247l_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecea1ed-4007-409c-a53f-792ab0d20709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"The', 'height', 'of', 'his', 'glory\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--', 'deploring', 'his', 'unaccountable', 'abdication', '.', '\"Of', 'course', \"it's\", 'going', 'to', 'send', 'the', 'value', 'of', 'my', 'picture', \"'way\", 'up', ';', 'but', 'I', \"don't\", 'think', 'of', 'that', ',', 'Mr', '.', 'Rickham', '--', 'the', 'loss', 'to', 'Arrt', 'is', 'all', 'I', 'think', 'of', '.', '\"', 'The', 'word', ',', 'on', 'Mrs', '.', \"Thwing's\", 'lips', ',', 'multiplied', 'its', '_', 'rs', '_', 'as', 'though', 'they', 'were', 'reflected', 'in', 'an', 'endless', 'vista', 'of', 'mirrors', '.', 'And', 'it', 'was', 'not', 'only', 'the', 'Mrs', '.', 'Thwings', 'who', 'mourned', '.', 'Had', 'not', 'the', 'exquisite', 'Hermia', 'Croft', ',', 'at', 'the', 'last', 'Grafton', 'Gallery', 'show', ',', 'stopped', 'me', 'before', \"Gisburn's\", '\"Moon-dancers\"', 'to', 'say', ',', 'with']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(res_pre))"
      ],
      "metadata": {
        "id": "pnxecTlWs13v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b218227-9b66-4994-80a9-0526d0b2501d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Token IDs**"
      ],
      "metadata": {
        "id": "AhBFHpqg0Bs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating a list of unique tokens & sorting them alphabetically to determine vocabulary size**"
      ],
      "metadata": {
        "id": "futxc1L50InN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = sorted(set(res_pre))\n",
        "print(len(words))"
      ],
      "metadata": {
        "id": "SV0SCA1Vs2Bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812d5b51-4440-4ba8-ac29-66f9138ae8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {i:index for index , i in enumerate(words)}\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "hK8_Z_Wp0qT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d7a476-80c2-401a-a3cf-da2ff9d233a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'!': 0, '\"': 1, '\"Ah': 2, '\"Be': 3, '\"Begin': 4, '\"By': 5, '\"Come': 6, '\"Destroyed': 7, '\"Don\\'t': 8, '\"Gisburns\"': 9, '\"Grindles': 10, '\"Hang': 11, '\"Has': 12, '\"How': 13, '\"I': 14, '\"I\\'d': 15, '\"If': 16, '\"It': 17, '\"It\\'s': 18, '\"Jack': 19, '\"Money\\'s': 20, '\"Moon-dancers\"': 21, '\"Mr': 22, '\"Mrs': 23, '\"My': 24, '\"Never': 25, '\"Of': 26, '\"Oh': 27, '\"Once': 28, '\"Only': 29, '\"Or': 30, '\"That': 31, '\"The': 32, '\"Then': 33, '\"There': 34, '\"This': 35, '\"We': 36, '\"Well': 37, '\"What': 38, '\"When': 39, '\"Why': 40, '\"Yes': 41, '\"You': 42, '\"but': 43, '\"deadening': 44, '\"dragged': 45, '\"effects\"': 46, '\"interesting\"': 47, '\"lift': 48, '\"obituary\"': 49, '\"strongest': 50, '\"strongly\"': 51, '\"sweetly\"': 52, \"'\": 53, \"'Are\": 54, \"'It's\": 55, \"'coming'\": 56, \"'done'\": 57, \"'subject\": 58, \"'technique'\": 59, \"'way\": 60, '(': 61, ')': 62, ',': 63, '--': 64, '.': 65, ':': 66, ';': 67, '?': 68, 'A': 69, 'Among': 70, 'And': 71, 'Arrt': 72, 'As': 73, 'At': 74, 'Burlington': 75, 'But': 76, 'By': 77, 'Carlo': 78, 'Chicago': 79, 'Claude': 80, 'Croft': 81, 'Devonshire': 82, \"Don't\": 83, 'Dubarry': 84, 'Emperors': 85, 'Florence': 86, 'For': 87, 'Gallery': 88, 'Gideon': 89, 'Gisburn': 90, \"Gisburn's\": 91, 'Grafton': 92, 'Greek': 93, 'Grindle': 94, \"Grindle's\": 95, 'HAD': 96, 'Had': 97, 'He': 98, 'Her': 99, 'Hermia': 100, \"Hermia's\": 101, 'His': 102, 'I': 103, \"I'd\": 104, \"I'll\": 105, \"I've\": 106, 'If': 107, 'In': 108, 'It': 109, 'Jack': 110, \"Jack's\": 111, 'Jove': 112, 'Just': 113, 'Lord': 114, 'Made': 115, 'Miss': 116, 'Monte': 117, 'Mr': 118, 'Mrs': 119, 'My': 120, 'No': 121, 'Now': 122, 'Nutley': 123, 'Of': 124, 'On': 125, 'Only': 126, 'Perhaps': 127, 'Poor': 128, 'Professional': 129, 'Renaissance': 130, 'Rickham': 131, 'Riviera': 132, 'Rome': 133, 'Russian': 134, 'Sevres': 135, 'She': 136, \"She's\": 137, 'Stroud': 138, \"Stroud's\": 139, 'Strouds': 140, 'Suddenly': 141, 'That': 142, \"That's\": 143, 'The': 144, 'Then': 145, 'There': 146, 'They': 147, 'Those': 148, 'Though': 149, 'Thwing': 150, \"Thwing's\": 151, 'Thwings': 152, 'To': 153, 'Usually': 154, 'Venetian': 155, 'Victor': 156, 'Was': 157, 'Well': 158, 'What': 159, 'When': 160, 'Why': 161, 'Yes': 162, 'You': 163, '_': 164, 'a': 165, 'abdication': 166, 'able': 167, 'about': 168, 'above': 169, 'abruptly': 170, 'absolute': 171, 'absorbed': 172, 'absurdity': 173, 'academic': 174, 'accuse': 175, 'accustomed': 176, 'across': 177, 'activity': 178, 'add': 179, 'added': 180, 'admirers': 181, 'adopted': 182, 'adulation': 183, 'advance': 184, 'aesthetic': 185, 'affect': 186, 'afraid': 187, 'after': 188, 'afterward': 189, 'again': 190, 'again\"': 191, 'ago': 192, 'ah': 193, 'air': 194, 'alive': 195, 'all': 196, 'almost': 197, 'alone': 198, 'along': 199, 'always': 200, 'am': 201, 'amazement': 202, 'amid': 203, 'among': 204, 'amplest': 205, 'amusing': 206, 'an': 207, 'and': 208, 'another': 209, 'answer': 210, 'answered': 211, 'any': 212, 'anything': 213, 'anywhere': 214, 'apparent': 215, 'apparently': 216, 'appearance': 217, 'appeared': 218, 'appointed': 219, 'are': 220, 'arm': 221, 'arm-chair': 222, 'arm-chairs': 223, 'arms': 224, 'art': 225, 'articles': 226, 'artist': 227, 'as': 228, 'aside': 229, 'asked': 230, 'at': 231, 'atmosphere': 232, 'atom': 233, 'attack': 234, 'attention': 235, 'attitude': 236, 'audacities': 237, 'away': 238, 'awful': 239, 'axioms': 240, 'azaleas': 241, 'back': 242, 'background': 243, 'balance': 244, 'balancing': 245, 'balustraded': 246, 'basking': 247, 'bath-rooms': 248, 'be': 249, 'beaming': 250, 'bean-stalk': 251, 'bear': 252, 'beard': 253, 'beauty': 254, 'became': 255, 'because': 256, 'becoming': 257, 'bed': 258, 'been': 259, 'before': 260, 'began': 261, 'begun': 262, 'behind': 263, 'being': 264, 'believed': 265, 'beneath': 266, 'bespoke': 267, 'better': 268, 'between': 269, 'big': 270, 'bits': 271, 'bitterness': 272, 'blocked': 273, 'born': 274, 'borne': 275, 'boudoir': 276, 'bravura': 277, 'break': 278, 'breaking': 279, 'breathing': 280, 'bric-a-brac': 281, 'briefly': 282, 'brings': 283, 'bronzes': 284, 'brought': 285, 'brown': 286, 'brush': 287, 'bull': 288, 'business': 289, 'but': 290, 'buying': 291, 'by': 292, 'called': 293, 'came': 294, 'can': 295, 'canvas': 296, 'canvases': 297, 'cards': 298, 'care': 299, 'career': 300, 'caught': 301, 'central': 302, 'chair': 303, 'chap': 304, 'characteristic': 305, 'charming': 306, 'cheap': 307, 'check': 308, 'cheeks': 309, 'chest': 310, 'chimney-piece': 311, 'chucked': 312, 'cigar': 313, 'cigarette': 314, 'cigars': 315, 'circulation': 316, 'circumstance': 317, \"circus-clown's\": 318, 'claimed': 319, 'clasping': 320, 'clear': 321, 'cleverer': 322, 'close': 323, 'clue': 324, 'coat': 325, 'collapsed': 326, 'colour': 327, 'come': 328, 'comfortable': 329, 'coming': 330, 'companion': 331, 'compared': 332, 'complex': 333, 'confident': 334, 'congesting': 335, 'conjugal': 336, 'constraint': 337, 'consummate': 338, 'contended': 339, 'continued': 340, 'corner': 341, 'corrected': 342, 'could': 343, \"couldn't\": 344, 'count': 345, 'countenance': 346, 'couple': 347, 'course': 348, 'covered': 349, 'craft': 350, 'cried': 351, 'crossed': 352, 'crowned': 353, 'crumbled': 354, 'cry': 355, 'cured': 356, 'curiosity': 357, 'curious': 358, 'current': 359, 'curtains': 360, 'dabble': 361, 'damask': 362, 'dark': 363, 'dashed': 364, 'day': 365, 'days': 366, 'dead': 367, 'dear': 368, 'deep': 369, \"deerhound's\": 370, 'degree': 371, 'delicate': 372, 'demand': 373, 'denied': 374, 'deploring': 375, 'deprecating': 376, 'deprecatingly': 377, 'desire': 378, 'destroyed': 379, 'destruction': 380, 'desultory': 381, 'detail': 382, 'diagnosis': 383, 'did': 384, \"didn't\": 385, 'died': 386, 'dim': 387, 'dimmest': 388, 'dingy': 389, 'dining-room': 390, 'disarming': 391, 'discovery': 392, 'discrimination': 393, 'discussion': 394, 'disdain': 395, 'disdained': 396, 'disease': 397, 'disguised': 398, 'display': 399, 'dissatisfied': 400, 'distinguished': 401, 'distract': 402, 'divert': 403, 'do': 404, \"doesn't\": 405, 'doing': 406, 'domestic': 407, \"don't\": 408, 'done': 409, 'donkey': 410, 'down': 411, 'dozen': 412, 'dragged': 413, 'drawing-room': 414, 'drawing-rooms': 415, 'drawn': 416, 'dress-closets': 417, 'drew': 418, 'dropped': 419, 'each': 420, 'earth': 421, 'ease': 422, 'easel': 423, 'easy': 424, 'echoed': 425, 'economy': 426, 'effect': 427, 'efforts': 428, 'egregious': 429, 'eighteenth-century': 430, 'elbow': 431, 'elegant': 432, 'else': 433, 'embarrassed': 434, 'enabled': 435, 'end': 436, 'endless': 437, 'enjoy': 438, 'enlightenment': 439, 'enough': 440, 'ensuing': 441, 'equally': 442, 'equanimity': 443, 'escape': 444, 'established': 445, 'etching': 446, 'even': 447, 'event': 448, 'ever': 449, 'everlasting': 450, 'every': 451, 'exasperated': 452, 'except': 453, 'excuse': 454, 'excusing': 455, 'existed': 456, 'expected': 457, 'exquisite': 458, 'exquisitely': 459, 'extenuation': 460, 'exterminating': 461, 'extracting': 462, 'eye': 463, 'eyebrows': 464, 'eyes': 465, 'face': 466, 'faces': 467, 'fact': 468, 'faded': 469, 'failed': 470, 'failure': 471, 'fair': 472, 'faith': 473, 'false': 474, 'familiar': 475, 'famille-verte': 476, 'fancy': 477, 'fashionable': 478, 'fate': 479, 'feather': 480, 'feet': 481, 'fell': 482, 'fellow': 483, 'felt': 484, 'few': 485, 'fewer': 486, 'finality': 487, 'find': 488, 'fingers': 489, 'first': 490, 'fit': 491, 'fitting': 492, 'five': 493, 'flash': 494, 'flashed': 495, 'florid': 496, 'flowers': 497, 'fluently': 498, 'flung': 499, 'follow': 500, 'followed': 501, 'fond': 502, 'footstep': 503, 'for': 504, 'forced': 505, 'forcing': 506, 'forehead': 507, 'foreign': 508, 'foreseen': 509, 'forgive': 510, 'forgotten': 511, 'form': 512, 'formed': 513, 'forming': 514, 'forward': 515, 'fostered': 516, 'found': 517, 'foundations': 518, 'fragment': 519, 'fragments': 520, 'frame': 521, 'frames': 522, 'frequently': 523, \"friend's\": 524, 'from': 525, 'full': 526, 'fullest': 527, 'furiously': 528, 'furrowed': 529, 'garlanded': 530, 'garlands': 531, 'gave': 532, 'genial': 533, 'genius': 534, 'gesture': 535, 'get': 536, 'getting': 537, 'give': 538, 'given': 539, 'glad': 540, 'glanced': 541, 'glimpse': 542, 'gloried': 543, 'glory': 544, 'glory\"': 545, 'go': 546, 'going': 547, 'gone': 548, 'good': 549, 'good-breeding': 550, 'good-humoured': 551, 'got': 552, 'grace': 553, 'gradually': 554, 'gray': 555, 'grayish': 556, 'great': 557, 'greatest': 558, 'greatness': 559, 'grew': 560, 'groping': 561, 'growing': 562, 'had': 563, \"hadn't\": 564, 'hair': 565, 'half': 566, 'half-light': 567, 'half-mechanically': 568, 'hall': 569, 'hand': 570, 'hands': 571, 'handsome': 572, 'hanging': 573, 'happen': 574, 'happened': 575, 'hard': 576, 'hardly': 577, 'has': 578, 'have': 579, \"haven't\": 580, 'having': 581, 'he': 582, \"he'd\": 583, \"he's\": 584, 'head': 585, 'hear': 586, 'heard': 587, 'heart': 588, 'height': 589, 'her': 590, 'here': 591, 'hermit': 592, 'herself': 593, 'hesitations': 594, 'hide': 595, 'high': 596, 'him': 597, 'himself': 598, 'hint': 599, 'his': 600, 'history': 601, 'holding': 602, 'home': 603, 'honour': 604, 'hooded': 605, 'hostess': 606, 'hot-house': 607, 'hour': 608, 'hours': 609, 'house': 610, 'how': 611, \"how'\": 612, 'hung': 613, 'husband': 614, \"husband's\": 615, 'idea': 616, 'idle': 617, 'idling': 618, 'if': 619, 'immediately': 620, 'in': 621, 'incense': 622, 'indifferent': 623, 'inevitable': 624, 'inevitably': 625, 'inflexible': 626, 'insensible': 627, 'insignificant': 628, 'instinctively': 629, 'instructive': 630, 'interesting': 631, 'into': 632, 'ironic': 633, 'irony': 634, 'irrelevance': 635, 'irrevocable': 636, 'is': 637, 'it': 638, \"it's\": 639, 'its': 640, 'itself': 641, 'jardiniere': 642, 'jealousy': 643, 'just': 644, 'keep': 645, 'kept': 646, 'kind': 647, 'knees': 648, 'knew': 649, 'know': 650, 'known': 651, 'laid': 652, 'lair': 653, 'landing': 654, 'language': 655, 'last': 656, 'late': 657, 'later': 658, 'latter': 659, \"latter's\": 660, 'laugh': 661, 'laughed': 662, 'lay': 663, 'leading': 664, 'lean': 665, 'learned': 666, 'least': 667, 'leathery': 668, 'leave': 669, 'led': 670, 'left': 671, 'leisure': 672, 'lends': 673, 'lent': 674, 'let': 675, 'lies': 676, 'life': 677, 'life-likeness': 678, 'lift': 679, 'lifted': 680, 'light': 681, 'lightly': 682, 'like': 683, 'liked': 684, 'line': 685, 'lines': 686, 'lingered': 687, 'lips': 688, 'lit': 689, 'little': 690, 'live': 691, 'loathing': 692, 'long': 693, 'longed': 694, 'longer': 695, 'look': 696, 'looked': 697, 'looking': 698, 'lose': 699, 'loss': 700, 'lounging': 701, 'lovely': 702, 'lucky': 703, 'lump': 704, 'luncheon-table': 705, 'luxury': 706, 'lying': 707, 'made': 708, 'make': 709, 'man': 710, 'manage': 711, 'managed': 712, 'mantel-piece': 713, 'marble': 714, 'married': 715, 'may': 716, 'me': 717, 'meant': 718, 'mediocrity\"': 719, 'medium': 720, 'mentioned': 721, 'mere': 722, 'merely': 723, 'met': 724, 'might': 725, 'mighty': 726, \"millionaire's\": 727, 'mine': 728, 'minute': 729, 'minutes': 730, 'mirrors': 731, 'modest': 732, 'modesty': 733, 'moment': 734, 'money': 735, 'monumental': 736, 'mood': 737, 'morbidly': 738, 'more': 739, 'most': 740, 'mourn': 741, 'mourned': 742, 'moustache': 743, 'moved': 744, 'much': 745, 'muddling': 746, 'multiplied': 747, 'murmur': 748, 'muscles': 749, 'must': 750, 'my': 751, 'myself': 752, 'mysterious': 753, 'naive': 754, 'near': 755, 'nearly': 756, 'negatived': 757, 'nervous': 758, 'nervousness': 759, 'neutral': 760, 'never': 761, 'next': 762, 'no': 763, 'none': 764, 'not': 765, 'note': 766, 'nothing': 767, 'now': 768, 'nymphs': 769, 'oak': 770, 'object': 771, 'objects': 772, 'occurred': 773, 'oddly': 774, 'of': 775, 'off': 776, 'often': 777, 'oh': 778, 'old': 779, 'on': 780, 'once': 781, 'one': 782, 'ones': 783, 'only': 784, 'onto': 785, 'open': 786, 'or': 787, 'other': 788, 'our': 789, 'ourselves': 790, 'out': 791, 'outline': 792, 'oval': 793, 'over': 794, 'own': 795, 'packed': 796, 'paid': 797, 'paint': 798, 'painted': 799, 'painter': 800, 'painting': 801, 'pale': 802, 'paled': 803, 'palm-trees': 804, 'panel': 805, 'panelling': 806, 'pardonable': 807, 'pardoned': 808, 'part': 809, 'passages': 810, 'passing': 811, 'past': 812, 'pastels': 813, 'pathos': 814, 'patient': 815, 'people': 816, 'perceptible': 817, 'perfect': 818, 'persistence': 819, 'persuasively': 820, 'phrase': 821, 'picture': 822, 'pictures': 823, 'pines': 824, 'pink': 825, 'place': 826, 'placed': 827, 'plain': 828, 'platitudes': 829, 'pleased': 830, 'pockets': 831, 'point': 832, 'poised': 833, 'poor': 834, 'portrait': 835, 'posing': 836, 'possessed': 837, 'poverty': 838, 'predicted': 839, 'preliminary': 840, 'presenting': 841, 'prestidigitation': 842, 'pretty': 843, 'previous': 844, 'price': 845, 'pride': 846, 'princely': 847, 'prism': 848, 'problem': 849, 'proclaiming': 850, 'prodigious': 851, 'profusion': 852, 'protest': 853, 'prove': 854, 'public': 855, 'purblind': 856, 'purely': 857, 'pushed': 858, 'put': 859, 'qualities': 860, 'quality': 861, 'queerly': 862, 'question': 863, 'quickly': 864, 'quietly': 865, 'quite': 866, 'quote': 867, 'rain': 868, 'raised': 869, 'random': 870, 'rather': 871, 'real': 872, 'really': 873, 'reared': 874, 'reason': 875, 'reassurance': 876, 'recovering': 877, 'recreated': 878, 'reflected': 879, 'reflection': 880, 'regrets': 881, 'relatively': 882, 'remained': 883, 'remember': 884, 'reminded': 885, 'repeating': 886, 'represented': 887, 'reproduction': 888, 'resented': 889, 'resolve': 890, 'resources': 891, 'rest': 892, 'rich': 893, 'ridiculous': 894, 'robbed': 895, 'romantic': 896, 'room': 897, 'rose': 898, 'rs': 899, 'rule': 900, 'run': 901, 'said': 902, 'same': 903, 'satisfaction': 904, 'savour': 905, 'saw': 906, 'say': 907, 'saying': 908, 'says': 909, 'scorn': 910, 'scornful': 911, 'secret': 912, 'see': 913, 'seemed': 914, 'seen': 915, 'self-confident': 916, 'send': 917, 'sensation': 918, 'sensitive': 919, 'sent': 920, 'serious': 921, 'set': 922, 'sex': 923, 'shade': 924, 'shaking': 925, 'shall': 926, 'she': 927, \"she's\": 928, 'shirked': 929, 'short': 930, 'should': 931, 'shoulder': 932, 'shoulders': 933, 'show': 934, 'showed': 935, 'showy': 936, 'shrug': 937, 'shrugged': 938, 'sight': 939, 'sign': 940, 'silent': 941, 'silver': 942, 'similar': 943, 'simpleton': 944, 'simplifications': 945, 'simply': 946, 'since': 947, 'single': 948, 'sitter': 949, 'sitters': 950, 'sketch': 951, 'skill': 952, 'slight': 953, 'slightly': 954, 'slowly': 955, 'small': 956, 'smile': 957, 'smiling': 958, 'sneer': 959, 'so': 960, 'solace': 961, 'some': 962, 'somebody': 963, 'something': 964, 'spacious': 965, 'spaniel': 966, 'speaking-tubes': 967, 'speculations': 968, 'spite': 969, 'splash': 970, 'square': 971, 'stairs': 972, 'stammer': 973, 'stand': 974, 'standing': 975, 'started': 976, 'stay': 977, 'still': 978, 'stocked': 979, 'stood': 980, 'stopped': 981, 'stopping': 982, 'straddling': 983, 'straight': 984, 'strain': 985, 'straining': 986, 'strange': 987, 'straw': 988, 'stream': 989, 'stroke': 990, 'strokes': 991, 'strolled': 992, 'struck': 993, 'studio': 994, 'stuff': 995, 'subject': 996, 'substantial': 997, 'suburban': 998, 'such': 999, 'suddenly': 1000, 'suffered': 1001, 'sugar': 1002, 'suggested': 1003, 'sunburn': 1004, 'sunburnt': 1005, 'sunlit': 1006, 'superb': 1007, 'sure': 1008, 'surest': 1009, 'surface': 1010, 'surprise': 1011, 'surprised': 1012, 'surrounded': 1013, 'suspected': 1014, 'sweetness': 1015, 'swelling': 1016, 'swept': 1017, 'swum': 1018, 'table': 1019, 'take': 1020, 'taken': 1021, 'talking': 1022, 'tea': 1023, 'tears': 1024, 'technicalities': 1025, 'tell': 1026, 'tells': 1027, 'tempting': 1028, 'terra-cotta': 1029, 'terrace': 1030, 'terraces': 1031, 'terribly': 1032, 'than': 1033, 'that': 1034, 'the': 1035, 'their': 1036, 'them': 1037, 'then': 1038, 'there': 1039, \"there's\": 1040, 'therefore': 1041, 'they': 1042, \"they're\": 1043, 'thin': 1044, 'thing': 1045, 'things': 1046, 'think': 1047, 'this': 1048, 'thither': 1049, 'those': 1050, 'though': 1051, 'thought': 1052, 'three': 1053, 'threshold': 1054, 'threw': 1055, 'through': 1056, 'throwing': 1057, 'tie': 1058, 'till': 1059, 'time': 1060, 'timorously': 1061, 'tinge': 1062, 'tips': 1063, 'tired': 1064, 'to': 1065, 'told': 1066, 'tone': 1067, 'tones': 1068, 'too': 1069, 'took': 1070, 'tottering': 1071, 'touched': 1072, 'toward': 1073, 'trace': 1074, 'trade': 1075, 'transmute': 1076, 'traps': 1077, 'travelled': 1078, 'tribute': 1079, 'tributes': 1080, 'tricks': 1081, 'tried': 1082, 'trouser-presses': 1083, 'true': 1084, 'truth': 1085, 'turned': 1086, 'twenty': 1087, 'twenty-four': 1088, 'twice': 1089, 'twirling': 1090, 'unaccountable': 1091, 'uncertain': 1092, 'under': 1093, 'underlay': 1094, 'underneath': 1095, 'understand': 1096, 'unexpected': 1097, 'untouched': 1098, 'unusual': 1099, 'up': 1100, 'up\"': 1101, 'up-stream': 1102, 'upon': 1103, 'upset': 1104, 'upstairs': 1105, 'us': 1106, 'used': 1107, 'usual': 1108, 'value': 1109, 'varnishing': 1110, 'vases': 1111, 'veins': 1112, 'velveteen': 1113, 'very': 1114, 'villa': 1115, 'vindicated': 1116, 'virtuosity': 1117, 'vista': 1118, 'vocation': 1119, 'voice': 1120, 'wall': 1121, 'wander': 1122, 'want': 1123, 'wanted': 1124, 'wants': 1125, 'was': 1126, \"wasn't\": 1127, 'watched': 1128, 'watching': 1129, 'water-colour': 1130, 'waves': 1131, 'way': 1132, 'weekly': 1133, 'weeks': 1134, \"weeks'\": 1135, 'welcome': 1136, 'went': 1137, 'were': 1138, 'what': 1139, 'when': 1140, 'whenever': 1141, 'where': 1142, 'which': 1143, 'while': 1144, 'white': 1145, 'white-panelled': 1146, 'who': 1147, 'whole': 1148, 'whom': 1149, 'why': 1150, 'wide': 1151, 'widow': 1152, 'wife': 1153, \"wife's\": 1154, 'wild': 1155, 'wincing': 1156, 'window-curtains': 1157, 'wish': 1158, 'with': 1159, 'without': 1160, \"wits'\": 1161, 'woman': 1162, 'women': 1163, \"won't\": 1164, 'wonder': 1165, 'wondered': 1166, 'word': 1167, 'work': 1168, 'working': 1169, 'worth': 1170, 'would': 1171, \"wouldn't\": 1172, 'year': 1173, 'years': 1174, 'yellow': 1175, 'yet': 1176, 'you': 1177, \"you'd\": 1178, \"you're\": 1179, 'younger': 1180, 'your': 1181, 'yourself': 1182}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Creating Tokenizer Class with 2 methods\n",
        "*   Method : 1 | Encode Method : Converting token to token IDs\n",
        "*  Method : 2 | Decode Method :  Converting token IDs to text\n",
        "\n"
      ],
      "metadata": {
        "id": "A4JZKIoA4yPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class tokens_encode_decode:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_2_int = vocab # this vocab is a dictionary in the form of tokens : index\n",
        "    self.int_2_str = {index:token for token,index in vocab.items()}\n",
        "  def encode(self, text):\n",
        "    pre_pro = re.split(r'([,.:;\"\\'()]|--|\\s)', text)\n",
        "    pre_pro = [item.strip() for item in pre_pro if item.strip()]\n",
        "    ids  = [self.str_2_int[index] for index in pre_pro]\n",
        "    return ids\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_2_str[token] for token in ids])\n",
        "    text = re.sub(r'([,.;:\\'?\"!]|--|\\s)',r'\\1',text)\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "efZxq9MD059P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sol = tokens_encode_decode(vocab)\n",
        "\n",
        "txt = \"Chicago is a  place to\"\n",
        "ids = sol.encode(txt)\n",
        "print(ids)\n"
      ],
      "metadata": {
        "id": "cM7B5CK_05_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e9e573-4ff8-4658-f4b4-f70b1f8405fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[79, 637, 165, 826, 1065]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "back_to_text = sol.decode(ids)\n",
        "print(back_to_text)"
      ],
      "metadata": {
        "id": "Z7bBdrBW06C5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07478c52-32ee-4d15-9be1-0d12ddbf0612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chicago is a place to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding Special text Tokens**"
      ],
      "metadata": {
        "id": "OCAVjFiWaNLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(set(res_pre))\n",
        "all_tokens.extend(['<|unk|>','<|endoftext|>'])\n",
        "\n",
        "vocab = {tokens:index for index,tokens in enumerate(all_tokens)}\n",
        "print(len(vocab)) #earlier the lenght was 1183 after adding these 2 tokens lenght is 1185"
      ],
      "metadata": {
        "id": "BPuwuJSF06Es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f79cc47-b68e-4d14-c9f3-3eee394234f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab.items())"
      ],
      "metadata": {
        "id": "-lJ0eIWF06I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e957832f-37f8-4fab-aeff-fcc4aecfab36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('!', 0), ('\"', 1), ('\"Ah', 2), ('\"Be', 3), ('\"Begin', 4), ('\"By', 5), ('\"Come', 6), ('\"Destroyed', 7), ('\"Don\\'t', 8), ('\"Gisburns\"', 9), ('\"Grindles', 10), ('\"Hang', 11), ('\"Has', 12), ('\"How', 13), ('\"I', 14), ('\"I\\'d', 15), ('\"If', 16), ('\"It', 17), ('\"It\\'s', 18), ('\"Jack', 19), ('\"Money\\'s', 20), ('\"Moon-dancers\"', 21), ('\"Mr', 22), ('\"Mrs', 23), ('\"My', 24), ('\"Never', 25), ('\"Of', 26), ('\"Oh', 27), ('\"Once', 28), ('\"Only', 29), ('\"Or', 30), ('\"That', 31), ('\"The', 32), ('\"Then', 33), ('\"There', 34), ('\"This', 35), ('\"We', 36), ('\"Well', 37), ('\"What', 38), ('\"When', 39), ('\"Why', 40), ('\"Yes', 41), ('\"You', 42), ('\"but', 43), ('\"deadening', 44), ('\"dragged', 45), ('\"effects\"', 46), ('\"interesting\"', 47), ('\"lift', 48), ('\"obituary\"', 49), ('\"strongest', 50), ('\"strongly\"', 51), ('\"sweetly\"', 52), (\"'\", 53), (\"'Are\", 54), (\"'It's\", 55), (\"'coming'\", 56), (\"'done'\", 57), (\"'subject\", 58), (\"'technique'\", 59), (\"'way\", 60), ('(', 61), (')', 62), (',', 63), ('--', 64), ('.', 65), (':', 66), (';', 67), ('?', 68), ('A', 69), ('Among', 70), ('And', 71), ('Arrt', 72), ('As', 73), ('At', 74), ('Burlington', 75), ('But', 76), ('By', 77), ('Carlo', 78), ('Chicago', 79), ('Claude', 80), ('Croft', 81), ('Devonshire', 82), (\"Don't\", 83), ('Dubarry', 84), ('Emperors', 85), ('Florence', 86), ('For', 87), ('Gallery', 88), ('Gideon', 89), ('Gisburn', 90), (\"Gisburn's\", 91), ('Grafton', 92), ('Greek', 93), ('Grindle', 94), (\"Grindle's\", 95), ('HAD', 96), ('Had', 97), ('He', 98), ('Her', 99), ('Hermia', 100), (\"Hermia's\", 101), ('His', 102), ('I', 103), (\"I'd\", 104), (\"I'll\", 105), (\"I've\", 106), ('If', 107), ('In', 108), ('It', 109), ('Jack', 110), (\"Jack's\", 111), ('Jove', 112), ('Just', 113), ('Lord', 114), ('Made', 115), ('Miss', 116), ('Monte', 117), ('Mr', 118), ('Mrs', 119), ('My', 120), ('No', 121), ('Now', 122), ('Nutley', 123), ('Of', 124), ('On', 125), ('Only', 126), ('Perhaps', 127), ('Poor', 128), ('Professional', 129), ('Renaissance', 130), ('Rickham', 131), ('Riviera', 132), ('Rome', 133), ('Russian', 134), ('Sevres', 135), ('She', 136), (\"She's\", 137), ('Stroud', 138), (\"Stroud's\", 139), ('Strouds', 140), ('Suddenly', 141), ('That', 142), (\"That's\", 143), ('The', 144), ('Then', 145), ('There', 146), ('They', 147), ('Those', 148), ('Though', 149), ('Thwing', 150), (\"Thwing's\", 151), ('Thwings', 152), ('To', 153), ('Usually', 154), ('Venetian', 155), ('Victor', 156), ('Was', 157), ('Well', 158), ('What', 159), ('When', 160), ('Why', 161), ('Yes', 162), ('You', 163), ('_', 164), ('a', 165), ('abdication', 166), ('able', 167), ('about', 168), ('above', 169), ('abruptly', 170), ('absolute', 171), ('absorbed', 172), ('absurdity', 173), ('academic', 174), ('accuse', 175), ('accustomed', 176), ('across', 177), ('activity', 178), ('add', 179), ('added', 180), ('admirers', 181), ('adopted', 182), ('adulation', 183), ('advance', 184), ('aesthetic', 185), ('affect', 186), ('afraid', 187), ('after', 188), ('afterward', 189), ('again', 190), ('again\"', 191), ('ago', 192), ('ah', 193), ('air', 194), ('alive', 195), ('all', 196), ('almost', 197), ('alone', 198), ('along', 199), ('always', 200), ('am', 201), ('amazement', 202), ('amid', 203), ('among', 204), ('amplest', 205), ('amusing', 206), ('an', 207), ('and', 208), ('another', 209), ('answer', 210), ('answered', 211), ('any', 212), ('anything', 213), ('anywhere', 214), ('apparent', 215), ('apparently', 216), ('appearance', 217), ('appeared', 218), ('appointed', 219), ('are', 220), ('arm', 221), ('arm-chair', 222), ('arm-chairs', 223), ('arms', 224), ('art', 225), ('articles', 226), ('artist', 227), ('as', 228), ('aside', 229), ('asked', 230), ('at', 231), ('atmosphere', 232), ('atom', 233), ('attack', 234), ('attention', 235), ('attitude', 236), ('audacities', 237), ('away', 238), ('awful', 239), ('axioms', 240), ('azaleas', 241), ('back', 242), ('background', 243), ('balance', 244), ('balancing', 245), ('balustraded', 246), ('basking', 247), ('bath-rooms', 248), ('be', 249), ('beaming', 250), ('bean-stalk', 251), ('bear', 252), ('beard', 253), ('beauty', 254), ('became', 255), ('because', 256), ('becoming', 257), ('bed', 258), ('been', 259), ('before', 260), ('began', 261), ('begun', 262), ('behind', 263), ('being', 264), ('believed', 265), ('beneath', 266), ('bespoke', 267), ('better', 268), ('between', 269), ('big', 270), ('bits', 271), ('bitterness', 272), ('blocked', 273), ('born', 274), ('borne', 275), ('boudoir', 276), ('bravura', 277), ('break', 278), ('breaking', 279), ('breathing', 280), ('bric-a-brac', 281), ('briefly', 282), ('brings', 283), ('bronzes', 284), ('brought', 285), ('brown', 286), ('brush', 287), ('bull', 288), ('business', 289), ('but', 290), ('buying', 291), ('by', 292), ('called', 293), ('came', 294), ('can', 295), ('canvas', 296), ('canvases', 297), ('cards', 298), ('care', 299), ('career', 300), ('caught', 301), ('central', 302), ('chair', 303), ('chap', 304), ('characteristic', 305), ('charming', 306), ('cheap', 307), ('check', 308), ('cheeks', 309), ('chest', 310), ('chimney-piece', 311), ('chucked', 312), ('cigar', 313), ('cigarette', 314), ('cigars', 315), ('circulation', 316), ('circumstance', 317), (\"circus-clown's\", 318), ('claimed', 319), ('clasping', 320), ('clear', 321), ('cleverer', 322), ('close', 323), ('clue', 324), ('coat', 325), ('collapsed', 326), ('colour', 327), ('come', 328), ('comfortable', 329), ('coming', 330), ('companion', 331), ('compared', 332), ('complex', 333), ('confident', 334), ('congesting', 335), ('conjugal', 336), ('constraint', 337), ('consummate', 338), ('contended', 339), ('continued', 340), ('corner', 341), ('corrected', 342), ('could', 343), (\"couldn't\", 344), ('count', 345), ('countenance', 346), ('couple', 347), ('course', 348), ('covered', 349), ('craft', 350), ('cried', 351), ('crossed', 352), ('crowned', 353), ('crumbled', 354), ('cry', 355), ('cured', 356), ('curiosity', 357), ('curious', 358), ('current', 359), ('curtains', 360), ('dabble', 361), ('damask', 362), ('dark', 363), ('dashed', 364), ('day', 365), ('days', 366), ('dead', 367), ('dear', 368), ('deep', 369), (\"deerhound's\", 370), ('degree', 371), ('delicate', 372), ('demand', 373), ('denied', 374), ('deploring', 375), ('deprecating', 376), ('deprecatingly', 377), ('desire', 378), ('destroyed', 379), ('destruction', 380), ('desultory', 381), ('detail', 382), ('diagnosis', 383), ('did', 384), (\"didn't\", 385), ('died', 386), ('dim', 387), ('dimmest', 388), ('dingy', 389), ('dining-room', 390), ('disarming', 391), ('discovery', 392), ('discrimination', 393), ('discussion', 394), ('disdain', 395), ('disdained', 396), ('disease', 397), ('disguised', 398), ('display', 399), ('dissatisfied', 400), ('distinguished', 401), ('distract', 402), ('divert', 403), ('do', 404), (\"doesn't\", 405), ('doing', 406), ('domestic', 407), (\"don't\", 408), ('done', 409), ('donkey', 410), ('down', 411), ('dozen', 412), ('dragged', 413), ('drawing-room', 414), ('drawing-rooms', 415), ('drawn', 416), ('dress-closets', 417), ('drew', 418), ('dropped', 419), ('each', 420), ('earth', 421), ('ease', 422), ('easel', 423), ('easy', 424), ('echoed', 425), ('economy', 426), ('effect', 427), ('efforts', 428), ('egregious', 429), ('eighteenth-century', 430), ('elbow', 431), ('elegant', 432), ('else', 433), ('embarrassed', 434), ('enabled', 435), ('end', 436), ('endless', 437), ('enjoy', 438), ('enlightenment', 439), ('enough', 440), ('ensuing', 441), ('equally', 442), ('equanimity', 443), ('escape', 444), ('established', 445), ('etching', 446), ('even', 447), ('event', 448), ('ever', 449), ('everlasting', 450), ('every', 451), ('exasperated', 452), ('except', 453), ('excuse', 454), ('excusing', 455), ('existed', 456), ('expected', 457), ('exquisite', 458), ('exquisitely', 459), ('extenuation', 460), ('exterminating', 461), ('extracting', 462), ('eye', 463), ('eyebrows', 464), ('eyes', 465), ('face', 466), ('faces', 467), ('fact', 468), ('faded', 469), ('failed', 470), ('failure', 471), ('fair', 472), ('faith', 473), ('false', 474), ('familiar', 475), ('famille-verte', 476), ('fancy', 477), ('fashionable', 478), ('fate', 479), ('feather', 480), ('feet', 481), ('fell', 482), ('fellow', 483), ('felt', 484), ('few', 485), ('fewer', 486), ('finality', 487), ('find', 488), ('fingers', 489), ('first', 490), ('fit', 491), ('fitting', 492), ('five', 493), ('flash', 494), ('flashed', 495), ('florid', 496), ('flowers', 497), ('fluently', 498), ('flung', 499), ('follow', 500), ('followed', 501), ('fond', 502), ('footstep', 503), ('for', 504), ('forced', 505), ('forcing', 506), ('forehead', 507), ('foreign', 508), ('foreseen', 509), ('forgive', 510), ('forgotten', 511), ('form', 512), ('formed', 513), ('forming', 514), ('forward', 515), ('fostered', 516), ('found', 517), ('foundations', 518), ('fragment', 519), ('fragments', 520), ('frame', 521), ('frames', 522), ('frequently', 523), (\"friend's\", 524), ('from', 525), ('full', 526), ('fullest', 527), ('furiously', 528), ('furrowed', 529), ('garlanded', 530), ('garlands', 531), ('gave', 532), ('genial', 533), ('genius', 534), ('gesture', 535), ('get', 536), ('getting', 537), ('give', 538), ('given', 539), ('glad', 540), ('glanced', 541), ('glimpse', 542), ('gloried', 543), ('glory', 544), ('glory\"', 545), ('go', 546), ('going', 547), ('gone', 548), ('good', 549), ('good-breeding', 550), ('good-humoured', 551), ('got', 552), ('grace', 553), ('gradually', 554), ('gray', 555), ('grayish', 556), ('great', 557), ('greatest', 558), ('greatness', 559), ('grew', 560), ('groping', 561), ('growing', 562), ('had', 563), (\"hadn't\", 564), ('hair', 565), ('half', 566), ('half-light', 567), ('half-mechanically', 568), ('hall', 569), ('hand', 570), ('hands', 571), ('handsome', 572), ('hanging', 573), ('happen', 574), ('happened', 575), ('hard', 576), ('hardly', 577), ('has', 578), ('have', 579), (\"haven't\", 580), ('having', 581), ('he', 582), (\"he'd\", 583), (\"he's\", 584), ('head', 585), ('hear', 586), ('heard', 587), ('heart', 588), ('height', 589), ('her', 590), ('here', 591), ('hermit', 592), ('herself', 593), ('hesitations', 594), ('hide', 595), ('high', 596), ('him', 597), ('himself', 598), ('hint', 599), ('his', 600), ('history', 601), ('holding', 602), ('home', 603), ('honour', 604), ('hooded', 605), ('hostess', 606), ('hot-house', 607), ('hour', 608), ('hours', 609), ('house', 610), ('how', 611), (\"how'\", 612), ('hung', 613), ('husband', 614), (\"husband's\", 615), ('idea', 616), ('idle', 617), ('idling', 618), ('if', 619), ('immediately', 620), ('in', 621), ('incense', 622), ('indifferent', 623), ('inevitable', 624), ('inevitably', 625), ('inflexible', 626), ('insensible', 627), ('insignificant', 628), ('instinctively', 629), ('instructive', 630), ('interesting', 631), ('into', 632), ('ironic', 633), ('irony', 634), ('irrelevance', 635), ('irrevocable', 636), ('is', 637), ('it', 638), (\"it's\", 639), ('its', 640), ('itself', 641), ('jardiniere', 642), ('jealousy', 643), ('just', 644), ('keep', 645), ('kept', 646), ('kind', 647), ('knees', 648), ('knew', 649), ('know', 650), ('known', 651), ('laid', 652), ('lair', 653), ('landing', 654), ('language', 655), ('last', 656), ('late', 657), ('later', 658), ('latter', 659), (\"latter's\", 660), ('laugh', 661), ('laughed', 662), ('lay', 663), ('leading', 664), ('lean', 665), ('learned', 666), ('least', 667), ('leathery', 668), ('leave', 669), ('led', 670), ('left', 671), ('leisure', 672), ('lends', 673), ('lent', 674), ('let', 675), ('lies', 676), ('life', 677), ('life-likeness', 678), ('lift', 679), ('lifted', 680), ('light', 681), ('lightly', 682), ('like', 683), ('liked', 684), ('line', 685), ('lines', 686), ('lingered', 687), ('lips', 688), ('lit', 689), ('little', 690), ('live', 691), ('loathing', 692), ('long', 693), ('longed', 694), ('longer', 695), ('look', 696), ('looked', 697), ('looking', 698), ('lose', 699), ('loss', 700), ('lounging', 701), ('lovely', 702), ('lucky', 703), ('lump', 704), ('luncheon-table', 705), ('luxury', 706), ('lying', 707), ('made', 708), ('make', 709), ('man', 710), ('manage', 711), ('managed', 712), ('mantel-piece', 713), ('marble', 714), ('married', 715), ('may', 716), ('me', 717), ('meant', 718), ('mediocrity\"', 719), ('medium', 720), ('mentioned', 721), ('mere', 722), ('merely', 723), ('met', 724), ('might', 725), ('mighty', 726), (\"millionaire's\", 727), ('mine', 728), ('minute', 729), ('minutes', 730), ('mirrors', 731), ('modest', 732), ('modesty', 733), ('moment', 734), ('money', 735), ('monumental', 736), ('mood', 737), ('morbidly', 738), ('more', 739), ('most', 740), ('mourn', 741), ('mourned', 742), ('moustache', 743), ('moved', 744), ('much', 745), ('muddling', 746), ('multiplied', 747), ('murmur', 748), ('muscles', 749), ('must', 750), ('my', 751), ('myself', 752), ('mysterious', 753), ('naive', 754), ('near', 755), ('nearly', 756), ('negatived', 757), ('nervous', 758), ('nervousness', 759), ('neutral', 760), ('never', 761), ('next', 762), ('no', 763), ('none', 764), ('not', 765), ('note', 766), ('nothing', 767), ('now', 768), ('nymphs', 769), ('oak', 770), ('object', 771), ('objects', 772), ('occurred', 773), ('oddly', 774), ('of', 775), ('off', 776), ('often', 777), ('oh', 778), ('old', 779), ('on', 780), ('once', 781), ('one', 782), ('ones', 783), ('only', 784), ('onto', 785), ('open', 786), ('or', 787), ('other', 788), ('our', 789), ('ourselves', 790), ('out', 791), ('outline', 792), ('oval', 793), ('over', 794), ('own', 795), ('packed', 796), ('paid', 797), ('paint', 798), ('painted', 799), ('painter', 800), ('painting', 801), ('pale', 802), ('paled', 803), ('palm-trees', 804), ('panel', 805), ('panelling', 806), ('pardonable', 807), ('pardoned', 808), ('part', 809), ('passages', 810), ('passing', 811), ('past', 812), ('pastels', 813), ('pathos', 814), ('patient', 815), ('people', 816), ('perceptible', 817), ('perfect', 818), ('persistence', 819), ('persuasively', 820), ('phrase', 821), ('picture', 822), ('pictures', 823), ('pines', 824), ('pink', 825), ('place', 826), ('placed', 827), ('plain', 828), ('platitudes', 829), ('pleased', 830), ('pockets', 831), ('point', 832), ('poised', 833), ('poor', 834), ('portrait', 835), ('posing', 836), ('possessed', 837), ('poverty', 838), ('predicted', 839), ('preliminary', 840), ('presenting', 841), ('prestidigitation', 842), ('pretty', 843), ('previous', 844), ('price', 845), ('pride', 846), ('princely', 847), ('prism', 848), ('problem', 849), ('proclaiming', 850), ('prodigious', 851), ('profusion', 852), ('protest', 853), ('prove', 854), ('public', 855), ('purblind', 856), ('purely', 857), ('pushed', 858), ('put', 859), ('qualities', 860), ('quality', 861), ('queerly', 862), ('question', 863), ('quickly', 864), ('quietly', 865), ('quite', 866), ('quote', 867), ('rain', 868), ('raised', 869), ('random', 870), ('rather', 871), ('real', 872), ('really', 873), ('reared', 874), ('reason', 875), ('reassurance', 876), ('recovering', 877), ('recreated', 878), ('reflected', 879), ('reflection', 880), ('regrets', 881), ('relatively', 882), ('remained', 883), ('remember', 884), ('reminded', 885), ('repeating', 886), ('represented', 887), ('reproduction', 888), ('resented', 889), ('resolve', 890), ('resources', 891), ('rest', 892), ('rich', 893), ('ridiculous', 894), ('robbed', 895), ('romantic', 896), ('room', 897), ('rose', 898), ('rs', 899), ('rule', 900), ('run', 901), ('said', 902), ('same', 903), ('satisfaction', 904), ('savour', 905), ('saw', 906), ('say', 907), ('saying', 908), ('says', 909), ('scorn', 910), ('scornful', 911), ('secret', 912), ('see', 913), ('seemed', 914), ('seen', 915), ('self-confident', 916), ('send', 917), ('sensation', 918), ('sensitive', 919), ('sent', 920), ('serious', 921), ('set', 922), ('sex', 923), ('shade', 924), ('shaking', 925), ('shall', 926), ('she', 927), (\"she's\", 928), ('shirked', 929), ('short', 930), ('should', 931), ('shoulder', 932), ('shoulders', 933), ('show', 934), ('showed', 935), ('showy', 936), ('shrug', 937), ('shrugged', 938), ('sight', 939), ('sign', 940), ('silent', 941), ('silver', 942), ('similar', 943), ('simpleton', 944), ('simplifications', 945), ('simply', 946), ('since', 947), ('single', 948), ('sitter', 949), ('sitters', 950), ('sketch', 951), ('skill', 952), ('slight', 953), ('slightly', 954), ('slowly', 955), ('small', 956), ('smile', 957), ('smiling', 958), ('sneer', 959), ('so', 960), ('solace', 961), ('some', 962), ('somebody', 963), ('something', 964), ('spacious', 965), ('spaniel', 966), ('speaking-tubes', 967), ('speculations', 968), ('spite', 969), ('splash', 970), ('square', 971), ('stairs', 972), ('stammer', 973), ('stand', 974), ('standing', 975), ('started', 976), ('stay', 977), ('still', 978), ('stocked', 979), ('stood', 980), ('stopped', 981), ('stopping', 982), ('straddling', 983), ('straight', 984), ('strain', 985), ('straining', 986), ('strange', 987), ('straw', 988), ('stream', 989), ('stroke', 990), ('strokes', 991), ('strolled', 992), ('struck', 993), ('studio', 994), ('stuff', 995), ('subject', 996), ('substantial', 997), ('suburban', 998), ('such', 999), ('suddenly', 1000), ('suffered', 1001), ('sugar', 1002), ('suggested', 1003), ('sunburn', 1004), ('sunburnt', 1005), ('sunlit', 1006), ('superb', 1007), ('sure', 1008), ('surest', 1009), ('surface', 1010), ('surprise', 1011), ('surprised', 1012), ('surrounded', 1013), ('suspected', 1014), ('sweetness', 1015), ('swelling', 1016), ('swept', 1017), ('swum', 1018), ('table', 1019), ('take', 1020), ('taken', 1021), ('talking', 1022), ('tea', 1023), ('tears', 1024), ('technicalities', 1025), ('tell', 1026), ('tells', 1027), ('tempting', 1028), ('terra-cotta', 1029), ('terrace', 1030), ('terraces', 1031), ('terribly', 1032), ('than', 1033), ('that', 1034), ('the', 1035), ('their', 1036), ('them', 1037), ('then', 1038), ('there', 1039), (\"there's\", 1040), ('therefore', 1041), ('they', 1042), (\"they're\", 1043), ('thin', 1044), ('thing', 1045), ('things', 1046), ('think', 1047), ('this', 1048), ('thither', 1049), ('those', 1050), ('though', 1051), ('thought', 1052), ('three', 1053), ('threshold', 1054), ('threw', 1055), ('through', 1056), ('throwing', 1057), ('tie', 1058), ('till', 1059), ('time', 1060), ('timorously', 1061), ('tinge', 1062), ('tips', 1063), ('tired', 1064), ('to', 1065), ('told', 1066), ('tone', 1067), ('tones', 1068), ('too', 1069), ('took', 1070), ('tottering', 1071), ('touched', 1072), ('toward', 1073), ('trace', 1074), ('trade', 1075), ('transmute', 1076), ('traps', 1077), ('travelled', 1078), ('tribute', 1079), ('tributes', 1080), ('tricks', 1081), ('tried', 1082), ('trouser-presses', 1083), ('true', 1084), ('truth', 1085), ('turned', 1086), ('twenty', 1087), ('twenty-four', 1088), ('twice', 1089), ('twirling', 1090), ('unaccountable', 1091), ('uncertain', 1092), ('under', 1093), ('underlay', 1094), ('underneath', 1095), ('understand', 1096), ('unexpected', 1097), ('untouched', 1098), ('unusual', 1099), ('up', 1100), ('up\"', 1101), ('up-stream', 1102), ('upon', 1103), ('upset', 1104), ('upstairs', 1105), ('us', 1106), ('used', 1107), ('usual', 1108), ('value', 1109), ('varnishing', 1110), ('vases', 1111), ('veins', 1112), ('velveteen', 1113), ('very', 1114), ('villa', 1115), ('vindicated', 1116), ('virtuosity', 1117), ('vista', 1118), ('vocation', 1119), ('voice', 1120), ('wall', 1121), ('wander', 1122), ('want', 1123), ('wanted', 1124), ('wants', 1125), ('was', 1126), (\"wasn't\", 1127), ('watched', 1128), ('watching', 1129), ('water-colour', 1130), ('waves', 1131), ('way', 1132), ('weekly', 1133), ('weeks', 1134), (\"weeks'\", 1135), ('welcome', 1136), ('went', 1137), ('were', 1138), ('what', 1139), ('when', 1140), ('whenever', 1141), ('where', 1142), ('which', 1143), ('while', 1144), ('white', 1145), ('white-panelled', 1146), ('who', 1147), ('whole', 1148), ('whom', 1149), ('why', 1150), ('wide', 1151), ('widow', 1152), ('wife', 1153), (\"wife's\", 1154), ('wild', 1155), ('wincing', 1156), ('window-curtains', 1157), ('wish', 1158), ('with', 1159), ('without', 1160), (\"wits'\", 1161), ('woman', 1162), ('women', 1163), (\"won't\", 1164), ('wonder', 1165), ('wondered', 1166), ('word', 1167), ('work', 1168), ('working', 1169), ('worth', 1170), ('would', 1171), (\"wouldn't\", 1172), ('year', 1173), ('years', 1174), ('yellow', 1175), ('yet', 1176), ('you', 1177), (\"you'd\", 1178), (\"you're\", 1179), ('younger', 1180), ('your', 1181), ('yourself', 1182), ('<|unk|>', 1183), ('<|endoftext|>', 1184)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i , item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "FC2wIiss06Ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3727f3-1bc7-4daa-b81a-1ebc37d1f155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1180)\n",
            "('your', 1181)\n",
            "('yourself', 1182)\n",
            "('<|unk|>', 1183)\n",
            "('<|endoftext|>', 1184)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerX:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_2_int = vocab\n",
        "    self.int_2_str = {index:token for token,index in vocab.items()}\n",
        "  def encode(self,text):\n",
        "    preprocessed = re.split(r'([.,!?;:_(){}\\[\\]\\s]|--)',text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "    preprocessed = [item if item in self.str_2_int else '<|unk|>' for item in preprocessed]\n",
        "    ids = [self.str_2_int[token] for token in preprocessed]\n",
        "    return ids\n",
        "  def decode(self,ids):\n",
        "    text = \" \".join([self.int_2_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "YP4sDDxE06Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerX(vocab)\n",
        "\n",
        "text_1 = \"Hello, do you like Tea?\"\n",
        "text_2 = \"In the sunlit terraces of the palace\"\n",
        "\n",
        "text = \" <|endoftext|> \".join((text_1,text_2))\n",
        "print(text)"
      ],
      "metadata": {
        "id": "O5ynWwrT06Qb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a5aaea-df35-4541-c18c-75bf8488ed86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like Tea? <|endoftext|> In the sunlit terraces of the palace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "GhvtyQqI06Ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6350304f-b8fd-45f0-f0e9-40baa1a7b904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1183, 63, 404, 1177, 683, 1183, 68, 1184, 108, 1035, 1006, 1031, 775, 1035, 1183]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = tokenizer.decode(ids)\n",
        "print(code)"
      ],
      "metadata": {
        "id": "xV3ezuQC06WZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce5e823-a6e7-4409-9d82-5555e590f7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|unk|>, do you like <|unk|>? <|endoftext|> In the sunlit terraces of the <|unk|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "VuhoiZBm06ag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "068edd50-7c3e-449e-daa1-25a4e5a2c569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>, do you like <|unk|>? <|endoftext|> In the sunlit terraces of the <|unk|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Byte Pair Encoding\n",
        "\n",
        "(https://github.com/openai/tiktoken)"
      ],
      "metadata": {
        "id": "DCXzsYiMg_-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tiktoken  #tiktoken is a fast BPE tokeniser for use with OpenAI's models."
      ],
      "metadata": {
        "id": "48mqPv9s06cY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a847e91-843c-4954-ebb9-160e548c00ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version :\", importlib.metadata.version('tiktoken'))"
      ],
      "metadata": {
        "id": "I5dnn4wF06gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51c02ab-9a28-4431-d1d6-e4f4915529a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version : 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "vZsn3lNH06io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"I don't like coffee or tea <|endoftext|> I have studied history all night, Are there anyunknownplaces here\"\n",
        "text = tokenizer.encode(sent, allowed_special = {'<|endoftext|>'})\n",
        "print(text)\n",
        "#If this word - anyunknownplaces would have come in word level tokenization then it would lead to Out Of Vocab problem & no Token ID would\n",
        "#have been generated. This word has been encoded in BPE , this word would have been broken down into sub words & then encoding has been done\n",
        "\n",
        "#Note : <|endoftext|> token has been given token ID 50256\n"
      ],
      "metadata": {
        "id": "IK2A5nVe06mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979ea1e1-7fb6-4ed1-93f7-03cdabfe974e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40, 836, 470, 588, 6891, 393, 8887, 220, 50256, 314, 423, 9713, 2106, 477, 1755, 11, 4231, 612, 597, 34680, 23625, 994]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(text)\n",
        "print(strings)"
      ],
      "metadata": {
        "id": "d61w6ttv06ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc08ab2-3c9d-4714-c961-a6e9abc9da24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't like coffee or tea <|endoftext|> I have studied history all night, Are there anyunknownplaces here\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example\n",
        "integers  = tokenizer.encode(\"Alfasm oops canghs\")\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)\n",
        "print(integers)"
      ],
      "metadata": {
        "id": "0mqPOKIX06sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9f84b2-6ebf-407d-fb77-4e7449c50ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alfasm oops canghs\n",
            "[32, 1652, 8597, 267, 2840, 460, 456, 82]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating input-target pairs"
      ],
      "metadata": {
        "id": "SqmDvQIXfuQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text = tokenizer.encode(raw_text) #this is a BPE Tokenizer\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "id": "UqU2owjN06uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5fb952-669d-446a-93ee-e358a964af73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample  = enc_text[50:]"
      ],
      "metadata": {
        "id": "sjOazv2u06y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4 # this tells us how many words are taken in input\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size + 1]\n",
        "print(f'x : {x}')\n",
        "print(f'y : {y}')\n",
        "#this means if the input is 290 next word is 4920 , if input is 290 + 4920 output is 2241, if input is 290 +\n",
        "#4920 +2241 , output is 287 , if input is 290,4920,2241 & 287 then output is 257"
      ],
      "metadata": {
        "id": "OQ40O-Dy061F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419e5687-b5dd-4f42-85e8-571d587b625a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x : [290, 4920, 2241, 287]\n",
            "y : [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#another representation of the above code\n",
        "for i in range(1, context_size +1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(context ,'----->', desired )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHvcM-2CzFv5",
        "outputId": "acb908d9-0e6f-4008-816c-a50731452087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] -----> 4920\n",
            "[290, 4920] -----> 2241\n",
            "[290, 4920, 2241] -----> 287\n",
            "[290, 4920, 2241, 287] -----> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size +1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(tokenizer.decode(context) ,'----->', tokenizer.decode([desired]))"
      ],
      "metadata": {
        "id": "E0PBD9AY065P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe5e996-0531-4db3-c9da-e3f480b3b1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ----->  established\n",
            " and established ----->  himself\n",
            " and established himself ----->  in\n",
            " and established himself in ----->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing DataLoader"
      ],
      "metadata": {
        "id": "iHPNcSYh48_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset , DataLoader\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt , tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    #Tokenizing the entire text\n",
        "    token_ids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0, len(token_ids) - max_length , stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n"
      ],
      "metadata": {
        "id": "ogKtQDef067K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size = 4, max_length = 256, stride = 128 , shuffle = True,\n",
        "                         drop_last = True, num_workers = 0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt , tokenizer , max_length , stride)\n",
        "  dataloader = DataLoader( dataset, batch_size = batch_size , shuffle = shuffle, drop_last = drop_last,\n",
        "                          num_workers = num_workers)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "cyEIGN0T06_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\",encoding = \"utf-8\") as f:\n",
        "  raw_text = f.read()"
      ],
      "metadata": {
        "id": "Rd7yq5ZO07BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"PyTorch Version:\" , torch.__version__)\n",
        "dataloader = create_dataloader_v1( raw_text , batch_size = 1, max_length = 4, stride = 1, shuffle = False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "id": "d-_mKJJf07Fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa4a56c-8ca2-4e7e-92ac-4f2dfbe9d2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.6.0+cu124\n",
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "id": "wrjqdSaR07Hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17572be4-794a-48f3-925e-86b288cd6128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size = 8, max_length = 4, stride = 4, shuffle = False)\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs : \\n\", inputs)\n",
        "print(\"\\nTargets : \\n\", targets)"
      ],
      "metadata": {
        "id": "b5zHEwZf07L_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81a5247-14d8-46a3-ffa6-a09f1c86d13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs : \n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets : \n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0WJUaOxt07OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQh3ELEb07SI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2Erxshn07UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJCOamSi07Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUHRHsDa07aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rkc0wIVE07e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BH4jpwyg07gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zU3Y84g107lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezRUICqY07nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tY0LjveK07rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LO9NKZhh07tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DN2l0L6l07xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lpyiul_o07za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdN9kb3P0731"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wT6tmJ39075k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KLaeNeta079n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "htX16LIO07_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFWOAmJQ08Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-X_4LaZ508Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ALPX6cG08Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDNzWFNo08Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0IhI4ay08PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55ltW1PF08RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IKf8zJLM08Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHOtLPiP08Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lppQsxhm08Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9WND_Es08bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9Lt-QX208fI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}